{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/pytorch-n-tensorflow-env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandriy-suh\u001b[0m (\u001b[33mandriy-suh-private\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/asukh/.netrc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "import clip\n",
    "import loraclip\n",
    "from torchvision import datasets, transforms\n",
    "from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "from datasets import load_dataset\n",
    "from encoder_utils import build_faiss_index, predict_with_faiss, compute_topk_accuracy, CLIPClassifier\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from gym import Trainer\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "clip_vit16_model, clip_preprocess = clip.load(\"ViT-B/16\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"./data\"\n",
    "os.makedirs(path_data, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "40000\n",
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "cifar100_dataset_train = datasets.CIFAR100(root=path_data, train=True, download=True, transform=clip_preprocess)\n",
    "cifar100_dataset_test = datasets.CIFAR100(root=path_data, train=False, download=True, transform=clip_preprocess)\n",
    "\n",
    "train_size = int(len(cifar100_dataset_train) * 0.8)\n",
    "val_size = len(cifar100_dataset_train) - train_size\n",
    "cifar100_train_x, cifar100_val_x = random_split(cifar100_dataset_train, [train_size, val_size])\n",
    "\n",
    "cifar100_loader_train = DataLoader(cifar100_train_x, batch_size=64, shuffle=True)\n",
    "cifar100_loader_val = DataLoader(cifar100_val_x, batch_size=64, shuffle=False)\n",
    "cifar100_loader_test = DataLoader(cifar100_dataset_test, batch_size=64, shuffle=False)\n",
    "print(len(cifar100_train_x))\n",
    "print(len(cifar100_val_x))\n",
    "print(len(cifar100_dataset_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ViT B/16: Zero-shot prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building FAISS Index: 100%|██████████| 782/782 [41:41<00:00,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index built with 50000 entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "faiss_labels, faiss_index = build_faiss_index(\n",
    "    dataloader=cifar100_loader_train,\n",
    "    model=clip_vit16_model,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth, predictions = predict_with_faiss(\n",
    "    dataloader=cifar100_loader_test,\n",
    "    model=clip_vit16_model,\n",
    "    faiss_index=faiss_index,\n",
    "    faiss_labels=faiss_labels,\n",
    "    device=device,\n",
    "    top_k=5,\n",
    "    distractor_classes=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 1 accuracy 0.9354\n"
     ]
    }
   ],
   "source": [
    "accuracy_top1 = compute_topk_accuracy(ground_truth, predictions, top_k=1)\n",
    "print('top 1 accuracy', accuracy_top1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 2 accuracy 0.9747\n"
     ]
    }
   ],
   "source": [
    "accuracy_top2 = compute_topk_accuracy(ground_truth, predictions, top_k=2)\n",
    "print('top 2 accuracy', accuracy_top2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ViT B/16: Train Clip Backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_vit16_cl_model = CLIPClassifier(clip_vit16_model, fine_tune=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/asukh/Work/VSCode/Python/ucu-la-proj/wandb/run-20250216_224120-qjq697nw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/andriy-suh-private/lora-project/runs/qjq697nw' target=\"_blank\">clip_vit16_full</a></strong> to <a href='https://wandb.ai/andriy-suh-private/lora-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/andriy-suh-private/lora-project' target=\"_blank\">https://wandb.ai/andriy-suh-private/lora-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/andriy-suh-private/lora-project/runs/qjq697nw' target=\"_blank\">https://wandb.ai/andriy-suh-private/lora-project/runs/qjq697nw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(clip_vit16_cl_model.parameters(), lr=1e-4)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=clip_vit16_cl_model,\n",
    "    train_loader=cifar100_loader_train,\n",
    "    val_loader=cifar100_loader_val,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=10,\n",
    "    hf_repo_name=\"ansu0122\",\n",
    "    experiment_name=\"clip_vit16_full\",\n",
    "    project_name=\"lora-project\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train/Accuracy</td><td>▁█</td></tr><tr><td>Train/Loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train/Accuracy</td><td>0.01847</td></tr><tr><td>Train/Loss</td><td>4.60496</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">clip_vit16_full</strong> at: <a href='https://wandb.ai/andriy-suh-private/lora-project/runs/qjq697nw' target=\"_blank\">https://wandb.ai/andriy-suh-private/lora-project/runs/qjq697nw</a><br/> View project at: <a href='https://wandb.ai/andriy-suh-private/lora-project' target=\"_blank\">https://wandb.ai/andriy-suh-private/lora-project</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250216_224120-qjq697nw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-n-tensorflow-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
