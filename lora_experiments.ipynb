{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/pytorch-n-tensorflow-env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandriy-suh\u001b[0m (\u001b[33mandriy-suh-private\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/asukh/.netrc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "from torchvision import datasets, transforms\n",
    "from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "from datasets import load_dataset\n",
    "from encoder_utils import build_faiss_index, predict_with_faiss, compute_topk_accuracy, CLIPClassifier\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from gym import Trainer\n",
    "import wandb\n",
    "import clip\n",
    "import lora_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "clip_vit16_model, clip_preprocess = clip.load(\"ViT-B/16\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"./data\"\n",
    "os.makedirs(path_data, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar100_dataset_train = datasets.CIFAR100(root=path_data, train=True, download=True, transform=clip_preprocess)\n",
    "cifar100_dataset_test = datasets.CIFAR100(root=path_data, train=False, download=True, transform=clip_preprocess)\n",
    "\n",
    "train_size = int(len(cifar100_dataset_train) * 0.8)\n",
    "val_size = len(cifar100_dataset_train) - train_size\n",
    "cifar100_train_x, cifar100_val_x = random_split(cifar100_dataset_train, [train_size, val_size])\n",
    "\n",
    "cifar100_loader_train = DataLoader(cifar100_train_x, batch_size=128, shuffle=True)\n",
    "cifar100_loader_val = DataLoader(cifar100_val_x, batch_size=128, shuffle=False)\n",
    "cifar100_loader_test = DataLoader(cifar100_dataset_test, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ViT B/16: Zero-shot prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building FAISS Index: 100%|██████████| 625/625 [15:01<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index built with 40000 entries.\n"
     ]
    }
   ],
   "source": [
    "faiss_labels, faiss_index = build_faiss_index(\n",
    "    dataloader=cifar100_loader_train,\n",
    "    model=clip_vit16_model,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting with FAISS: 100%|██████████| 157/157 [06:10<00:00,  2.36s/it]\n"
     ]
    }
   ],
   "source": [
    "ground_truth, predictions = predict_with_faiss(\n",
    "    dataloader=cifar100_loader_test,\n",
    "    model=clip_vit16_model,\n",
    "    faiss_index=faiss_index,\n",
    "    faiss_labels=faiss_labels,\n",
    "    device=device,\n",
    "    top_k=5,\n",
    "    distractor_classes=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 1 accuracy 0.6912\n"
     ]
    }
   ],
   "source": [
    "accuracy_top1 = compute_topk_accuracy(ground_truth, predictions, top_k=1)\n",
    "print('top 1 accuracy', accuracy_top1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 2 accuracy 0.8046\n"
     ]
    }
   ],
   "source": [
    "accuracy_top2 = compute_topk_accuracy(ground_truth, predictions, top_k=2)\n",
    "print('top 2 accuracy', accuracy_top2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ViT B/16: Train LoRA Adapter R=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n",
      "Unexpected keys: ['lora_text_projection']\n",
      " \n",
      "trainable params: 1448548 || all params: 150524005 || trainable%: 0.9623368711189952\n"
     ]
    }
   ],
   "source": [
    "# Setup the model\n",
    "r = 4\n",
    "clip_vit16_lora_r4 = lora_clip.build_LoRA_model(clip_vit16_model.state_dict(), r, 'vision').to(device)\n",
    "clip_vit16_lora_r4_cls = CLIPClassifier(clip_vit16_lora_r4, fine_tune=True).float().to(device)\n",
    "lora_clip.print_trainable_parameters(clip_vit16_lora_r4_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the trainer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(clip_vit16_lora_r4_cls.parameters(), lr=1e-4)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=clip_vit16_lora_r4_cls,\n",
    "    train_loader=cifar100_loader_train,\n",
    "    val_loader=cifar100_loader_val,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=10,\n",
    "    hf_repo_name=\"ansu0122/vit-lora\",\n",
    "    experiment_name=\"clip_vit16_lora_r4\",\n",
    "    project_name=\"lora-project\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ViT B/16: Train LoRA Adapter R=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the model\n",
    "r = 8\n",
    "clip_vit16_lora_r4 = lora_clip.build_LoRA_model(clip_vit16_model.state_dict(), r, 'vision').to(device)\n",
    "clip_vit16_lora_r4_cls = CLIPClassifier(clip_vit16_lora_r4, fine_tune=True).float().to(device)\n",
    "lora_clip.print_trainable_parameters(clip_vit16_lora_r4_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the trainer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(clip_vit16_lora_r4_cls.parameters(), lr=1e-4)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=clip_vit16_lora_r4_cls,\n",
    "    train_loader=cifar100_loader_train,\n",
    "    val_loader=cifar100_loader_val,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=10,\n",
    "    hf_repo_name=\"ansu0122/vit-lora\",\n",
    "    experiment_name=\"clip_vit16_lora_r4\",\n",
    "    project_name=\"lora-project\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Release Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "del clip_vit16_lora_r4_cls\n",
    "del trainer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in dir():\n",
    "    if isinstance(eval(var), torch.Tensor):\n",
    "        del globals()[var]\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Feb 16 23:24:41 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.127.05             Driver Version: 550.127.05     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        On  |   00000000:62:00.0 Off |                  N/A |\n",
      "| 30%   44C    P8             24W /  350W |    1548MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory allocated: 0.00 MB\n",
      "Memory reserved: 0.00 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Memory allocated: {torch.cuda.memory_allocated() / 1024 / 1024:.2f} MB\")\n",
    "print(f\"Memory reserved: {torch.cuda.memory_reserved() / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-n-tensorflow-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
