{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3.10-la-proj/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandriy-suh\u001b[0m (\u001b[33mandriy-suh-private\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "import clip\n",
    "import loraclip\n",
    "from torchvision import datasets, transforms\n",
    "from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "from datasets import load_dataset\n",
    "from encoder_utils import build_faiss_index, predict_with_faiss, compute_topk_accuracy, CLIPClassifier\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from gym import Trainer\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "clip_vit16_model, clip_preprocess = clip.load(\"ViT-B/16\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"./data\"\n",
    "os.makedirs(path_data, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar100_dataset_train = datasets.CIFAR100(root=path_data, train=True, download=True, transform=clip_preprocess)\n",
    "cifar100_dataset_test = datasets.CIFAR100(root=path_data, train=False, download=True, transform=clip_preprocess)\n",
    "\n",
    "train_size = int(len(cifar100_dataset_train) * 0.8)\n",
    "val_size = len(cifar100_dataset_train) - train_size\n",
    "cifar100_train_x, cifar100_val_x = random_split(cifar100_dataset_train, [train_size, val_size])\n",
    "\n",
    "cifar100_loader_train = DataLoader(cifar100_train_x, batch_size=128, shuffle=True)\n",
    "cifar100_loader_val = DataLoader(cifar100_val_x, batch_size=128, shuffle=False)\n",
    "cifar100_loader_test = DataLoader(cifar100_dataset_test, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ViT B/16: Zero-shot prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building FAISS Index: 100%|██████████| 625/625 [15:01<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index built with 40000 entries.\n"
     ]
    }
   ],
   "source": [
    "faiss_labels, faiss_index = build_faiss_index(\n",
    "    dataloader=cifar100_loader_train,\n",
    "    model=clip_vit16_model,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting with FAISS: 100%|██████████| 157/157 [06:10<00:00,  2.36s/it]\n"
     ]
    }
   ],
   "source": [
    "ground_truth, predictions = predict_with_faiss(\n",
    "    dataloader=cifar100_loader_test,\n",
    "    model=clip_vit16_model,\n",
    "    faiss_index=faiss_index,\n",
    "    faiss_labels=faiss_labels,\n",
    "    device=device,\n",
    "    top_k=5,\n",
    "    distractor_classes=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 1 accuracy 0.6912\n"
     ]
    }
   ],
   "source": [
    "accuracy_top1 = compute_topk_accuracy(ground_truth, predictions, top_k=1)\n",
    "print('top 1 accuracy', accuracy_top1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 2 accuracy 0.8046\n"
     ]
    }
   ],
   "source": [
    "accuracy_top2 = compute_topk_accuracy(ground_truth, predictions, top_k=2)\n",
    "print('top 2 accuracy', accuracy_top2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ViT B/16: Train LoRA Adapter R=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/ucu-la-proj/wandb/run-20250216_230605-ibbsta0f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/andriy-suh-private/lora-project/runs/ibbsta0f' target=\"_blank\">clip_vit16_full</a></strong> to <a href='https://wandb.ai/andriy-suh-private/lora-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/andriy-suh-private/lora-project' target=\"_blank\">https://wandb.ai/andriy-suh-private/lora-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/andriy-suh-private/lora-project/runs/ibbsta0f' target=\"_blank\">https://wandb.ai/andriy-suh-private/lora-project/runs/ibbsta0f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clip_vit16_lora_r4 = \n",
    "clip_vit16_cl_model = CLIPClassifier(clip_vit16_model, fine_tune=True).float().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(clip_vit16_cl_model.parameters(), lr=1e-4)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=clip_vit16_cl_model,\n",
    "    train_loader=cifar100_loader_train,\n",
    "    val_loader=cifar100_loader_val,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=10,\n",
    "    hf_repo_name=\"ansu0122/vit-lora\",\n",
    "    experiment_name=\"clip_vit16_lora_r4\",\n",
    "    project_name=\"lora-project\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ViT B/16: Train LoRA Adapter R=16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Release Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "del clip_vit16_cl_model\n",
    "del trainer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in dir():\n",
    "    if isinstance(eval(var), torch.Tensor):\n",
    "        del globals()[var]\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Feb 16 23:24:41 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.127.05             Driver Version: 550.127.05     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        On  |   00000000:62:00.0 Off |                  N/A |\n",
      "| 30%   44C    P8             24W /  350W |    1548MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory allocated: 584.70 MB\n",
      "Memory reserved: 634.00 MB\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"Memory allocated: {torch.cuda.memory_allocated() / 1024 / 1024:.2f} MB\")\n",
    "print(f\"Memory reserved: {torch.cuda.memory_reserved() / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10-la-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
