{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3.10-la-proj/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "import clip\n",
    "import loraclip\n",
    "from torchvision import datasets, transforms\n",
    "from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "from datasets import load_dataset # HuggingFace dedicated lib\n",
    "from encoder_utils import build_faiss_index, predict_with_faiss, compute_topk_accuracy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "clip_model, clip_preprocess = clip.load(\"ViT-B/16\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=224, interpolation=bicubic, max_size=None, antialias=True)\n",
       "    CenterCrop(size=(224, 224))\n",
       "    <function _convert_image_to_rgb at 0x7fbe90d57d90>\n",
       "    ToTensor()\n",
       "    Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711))\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"./data\"\n",
    "os.makedirs(path_data, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_dataset_train = datasets.CIFAR10(root=path_data, train=True, download=True, transform=clip_preprocess)\n",
    "cifar10_dataset_test = datasets.CIFAR10(root=path_data, train=False, download=True, transform=clip_preprocess)\n",
    "\n",
    "cifar10_loader_train = torch.utils.data.DataLoader(cifar10_dataset_train, batch_size=64, shuffle=True)\n",
    "cifar10_loader_test = torch.utils.data.DataLoader(cifar10_dataset_test, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting with FAISS:   0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6, 7, 0, 4, 9,\n",
      "        5, 2, 4, 0, 9, 6, 6, 5, 4, 5, 9, 2, 4, 1, 9, 5, 4, 6, 5, 6, 0, 9, 3, 9,\n",
      "        7, 6, 9, 8, 0, 3, 8, 8, 7, 7, 4, 6, 7, 3, 6, 3])\n",
      "tensor([[[[ 0.5289,  0.5289,  0.5289,  ..., -0.1134, -0.1134, -0.1134],\n",
      "          [ 0.5289,  0.5289,  0.5289,  ..., -0.1134, -0.1134, -0.1134],\n",
      "          [ 0.5143,  0.5143,  0.5143,  ..., -0.1134, -0.1134, -0.1134],\n",
      "          ...,\n",
      "          [-1.0039, -1.0039, -1.0039,  ..., -1.5003, -1.5003, -1.5149],\n",
      "          [-1.0185, -1.0185, -1.0185,  ..., -1.5003, -1.5003, -1.5149],\n",
      "          [-1.0185, -1.0185, -1.0185,  ..., -1.5003, -1.5003, -1.5149]],\n",
      "\n",
      "         [[-0.0712, -0.0712, -0.0712,  ..., -0.4764, -0.4914, -0.4914],\n",
      "          [-0.0712, -0.0712, -0.0712,  ..., -0.4764, -0.4914, -0.4914],\n",
      "          [-0.0712, -0.0712, -0.0712,  ..., -0.4764, -0.4914, -0.4914],\n",
      "          ...,\n",
      "          [-0.1613, -0.1613, -0.1613,  ..., -0.7616, -0.7766, -0.7766],\n",
      "          [-0.1613, -0.1613, -0.1613,  ..., -0.7616, -0.7766, -0.7766],\n",
      "          [-0.1613, -0.1613, -0.1613,  ..., -0.7616, -0.7766, -0.7766]],\n",
      "\n",
      "         [[-0.7834, -0.7834, -0.7834,  ..., -1.0110, -1.0110, -1.0110],\n",
      "          [-0.7834, -0.7834, -0.7834,  ..., -1.0110, -1.0110, -1.0110],\n",
      "          [-0.7834, -0.7834, -0.7834,  ..., -1.0110, -1.0110, -1.0110],\n",
      "          ...,\n",
      "          [ 0.7950,  0.7950,  0.8092,  ...,  0.0698,  0.0555,  0.0555],\n",
      "          [ 0.7950,  0.7950,  0.7950,  ...,  0.0698,  0.0555,  0.0555],\n",
      "          [ 0.7950,  0.7950,  0.7950,  ...,  0.0698,  0.0555,  0.0555]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6384,  1.6384,  1.6384,  ...,  1.5946,  1.5946,  1.5946],\n",
      "          [ 1.6384,  1.6384,  1.6384,  ...,  1.5946,  1.5946,  1.5946],\n",
      "          [ 1.6384,  1.6384,  1.6384,  ...,  1.5946,  1.5946,  1.5946],\n",
      "          ...,\n",
      "          [-0.5076, -0.5222, -0.5368,  ...,  0.9230,  0.9376,  0.9376],\n",
      "          [-0.5076, -0.5222, -0.5368,  ...,  0.9230,  0.9376,  0.9376],\n",
      "          [-0.5076, -0.5222, -0.5368,  ...,  0.9230,  0.9376,  0.9376]],\n",
      "\n",
      "         [[ 1.7747,  1.7747,  1.7747,  ...,  1.7297,  1.7297,  1.7297],\n",
      "          [ 1.7747,  1.7747,  1.7747,  ...,  1.7297,  1.7297,  1.7297],\n",
      "          [ 1.7747,  1.7747,  1.7747,  ...,  1.7297,  1.7297,  1.7297],\n",
      "          ...,\n",
      "          [-0.1913, -0.2063, -0.2063,  ...,  1.2495,  1.2495,  1.2645],\n",
      "          [-0.1913, -0.2063, -0.2063,  ...,  1.2495,  1.2495,  1.2645],\n",
      "          [-0.1913, -0.2063, -0.1913,  ...,  1.2495,  1.2495,  1.2645]],\n",
      "\n",
      "         [[ 1.8615,  1.8615,  1.8615,  ...,  1.8188,  1.8188,  1.8188],\n",
      "          [ 1.8615,  1.8615,  1.8615,  ...,  1.8188,  1.8188,  1.8188],\n",
      "          [ 1.8615,  1.8615,  1.8615,  ...,  1.8188,  1.8188,  1.8188],\n",
      "          ...,\n",
      "          [-0.2431, -0.2573, -0.2715,  ...,  1.3496,  1.3638,  1.3638],\n",
      "          [-0.2431, -0.2573, -0.2715,  ...,  1.3496,  1.3638,  1.3638],\n",
      "          [-0.2431, -0.2573, -0.2715,  ...,  1.3496,  1.3638,  1.3638]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4997,  0.4997,  0.4997,  ...,  1.6676,  1.6676,  1.6676],\n",
      "          [ 0.4997,  0.4997,  0.4997,  ...,  1.6676,  1.6676,  1.6676],\n",
      "          [ 0.4997,  0.4997,  0.4997,  ...,  1.6822,  1.6822,  1.6822],\n",
      "          ...,\n",
      "          [-1.3835, -1.3835, -1.3835,  ..., -1.6901, -1.6901, -1.6901],\n",
      "          [-1.3835, -1.3835, -1.3835,  ..., -1.6901, -1.6901, -1.6901],\n",
      "          [-1.3689, -1.3689, -1.3689,  ..., -1.6901, -1.6901, -1.6901]],\n",
      "\n",
      "         [[ 1.0844,  1.0844,  1.0844,  ...,  1.8498,  1.8498,  1.8498],\n",
      "          [ 1.0844,  1.0844,  1.0844,  ...,  1.8498,  1.8498,  1.8498],\n",
      "          [ 1.0844,  1.0844,  1.0844,  ...,  1.8648,  1.8648,  1.8648],\n",
      "          ...,\n",
      "          [-1.1368, -1.1368, -1.1368,  ..., -1.6320, -1.6320, -1.6320],\n",
      "          [-1.1218, -1.1218, -1.1218,  ..., -1.6320, -1.6320, -1.6320],\n",
      "          [-1.1218, -1.1218, -1.1218,  ..., -1.6320, -1.6320, -1.6320]],\n",
      "\n",
      "         [[ 1.6624,  1.6624,  1.6624,  ...,  2.0037,  2.0037,  2.0037],\n",
      "          [ 1.6624,  1.6624,  1.6624,  ...,  2.0179,  2.0179,  2.0179],\n",
      "          [ 1.6766,  1.6766,  1.6766,  ...,  2.0179,  2.0179,  2.0179],\n",
      "          ...,\n",
      "          [-0.8119, -0.8119, -0.8119,  ..., -1.3807, -1.3807, -1.3807],\n",
      "          [-0.7977, -0.7977, -0.7977,  ..., -1.3807, -1.3807, -1.3807],\n",
      "          [-0.7977, -0.7977, -0.7977,  ..., -1.3807, -1.3807, -1.3807]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.6463, -1.6463, -1.6463,  ...,  0.7479,  0.7479,  0.7479],\n",
      "          [-1.6463, -1.6463, -1.6463,  ...,  0.7479,  0.7479,  0.7479],\n",
      "          [-1.6463, -1.6463, -1.6463,  ...,  0.7479,  0.7479,  0.7479],\n",
      "          ...,\n",
      "          [-1.6463, -1.6317, -1.6317,  ...,  0.0909,  0.0909,  0.0909],\n",
      "          [-1.6609, -1.6463, -1.6463,  ...,  0.1055,  0.1055,  0.1055],\n",
      "          [-1.6609, -1.6463, -1.6463,  ...,  0.1055,  0.1055,  0.1055]],\n",
      "\n",
      "         [[-1.6020, -1.6020, -1.6020,  ...,  0.4090,  0.4090,  0.4090],\n",
      "          [-1.6020, -1.6020, -1.6020,  ...,  0.4090,  0.4090,  0.4090],\n",
      "          [-1.6020, -1.6020, -1.6020,  ...,  0.4090,  0.4090,  0.4090],\n",
      "          ...,\n",
      "          [-1.5120, -1.5120, -1.5120,  ..., -0.1463, -0.1463, -0.1463],\n",
      "          [-1.5120, -1.5120, -1.5120,  ..., -0.1313, -0.1313, -0.1313],\n",
      "          [-1.5270, -1.5270, -1.5270,  ..., -0.1313, -0.1313, -0.1313]],\n",
      "\n",
      "         [[-1.3380, -1.3380, -1.3380,  ...,  0.0698,  0.0698,  0.0698],\n",
      "          [-1.3380, -1.3380, -1.3380,  ...,  0.0698,  0.0698,  0.0698],\n",
      "          [-1.3380, -1.3380, -1.3380,  ...,  0.0698,  0.0698,  0.0698],\n",
      "          ...,\n",
      "          [-1.2811, -1.2527, -1.2527,  ..., -0.2857, -0.2857, -0.2857],\n",
      "          [-1.2811, -1.2669, -1.2669,  ..., -0.2857, -0.2857, -0.2857],\n",
      "          [-1.2811, -1.2669, -1.2669,  ..., -0.2715, -0.2715, -0.2715]]],\n",
      "\n",
      "\n",
      "        [[[-1.7923, -1.7923, -1.7923,  ..., -0.9018, -0.9018, -0.9018],\n",
      "          [-1.7923, -1.7923, -1.7923,  ..., -0.9018, -0.9018, -0.9018],\n",
      "          [-1.7923, -1.7923, -1.7923,  ..., -0.9018, -0.9018, -0.9018],\n",
      "          ...,\n",
      "          [-0.9310, -0.9018, -0.8726,  ..., -0.2740, -0.2594, -0.2594],\n",
      "          [-0.9164, -0.8872, -0.8580,  ..., -0.2302, -0.2156, -0.2156],\n",
      "          [-0.9164, -0.8872, -0.8580,  ..., -0.2156, -0.2010, -0.2010]],\n",
      "\n",
      "         [[-0.9717, -0.9717, -0.9717,  ..., -0.2963, -0.2963, -0.2963],\n",
      "          [-0.9717, -0.9717, -0.9717,  ..., -0.2963, -0.2963, -0.2963],\n",
      "          [-0.9717, -0.9717, -0.9717,  ..., -0.2813, -0.2963, -0.2963],\n",
      "          ...,\n",
      "          [-0.5065, -0.4914, -0.4614,  ...,  0.0939,  0.1089,  0.1239],\n",
      "          [-0.4914, -0.4764, -0.4464,  ...,  0.1239,  0.1389,  0.1539],\n",
      "          [-0.4764, -0.4614, -0.4314,  ...,  0.1389,  0.1689,  0.1839]],\n",
      "\n",
      "         [[-1.4802, -1.4802, -1.4802,  ..., -1.2669, -1.2669, -1.2669],\n",
      "          [-1.4802, -1.4802, -1.4802,  ..., -1.2669, -1.2669, -1.2669],\n",
      "          [-1.4660, -1.4660, -1.4660,  ..., -1.2527, -1.2527, -1.2527],\n",
      "          ...,\n",
      "          [-0.7123, -0.6839, -0.6555,  ..., -0.1293, -0.1151, -0.1009],\n",
      "          [-0.7123, -0.6839, -0.6555,  ..., -0.0867, -0.0724, -0.0582],\n",
      "          [-0.6981, -0.6697, -0.6412,  ..., -0.0582, -0.0440, -0.0298]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6676,  1.6530,  1.6384,  ..., -0.5222, -0.5222, -0.5222],\n",
      "          [ 1.6676,  1.6530,  1.6384,  ..., -0.5222, -0.5222, -0.5222],\n",
      "          [ 1.6676,  1.6530,  1.6384,  ..., -0.5222, -0.5222, -0.5222],\n",
      "          ...,\n",
      "          [ 0.2369,  0.2369,  0.2369,  ..., -0.1864, -0.2010, -0.2010],\n",
      "          [ 0.2223,  0.2223,  0.2223,  ..., -0.1572, -0.1718, -0.1718],\n",
      "          [ 0.2223,  0.2223,  0.2223,  ..., -0.1426, -0.1572, -0.1572]],\n",
      "\n",
      "         [[ 1.7297,  1.6997,  1.6697,  ..., -0.7616, -0.7616, -0.7766],\n",
      "          [ 1.7297,  1.6997,  1.6697,  ..., -0.7616, -0.7616, -0.7766],\n",
      "          [ 1.7297,  1.6997,  1.6697,  ..., -0.7616, -0.7616, -0.7766],\n",
      "          ...,\n",
      "          [ 0.3790,  0.3790,  0.3790,  ..., -0.0112, -0.0112, -0.0112],\n",
      "          [ 0.3640,  0.3640,  0.3640,  ...,  0.0188,  0.0188,  0.0188],\n",
      "          [ 0.3640,  0.3640,  0.3640,  ...,  0.0338,  0.0488,  0.0488]],\n",
      "\n",
      "         [[ 1.6482,  1.6198,  1.5771,  ..., -1.1674, -1.1674, -1.1674],\n",
      "          [ 1.6340,  1.6055,  1.5629,  ..., -1.1674, -1.1674, -1.1674],\n",
      "          [ 1.6340,  1.6055,  1.5629,  ..., -1.1674, -1.1674, -1.1674],\n",
      "          ...,\n",
      "          [ 0.3826,  0.3826,  0.3826,  ...,  0.0840,  0.0840,  0.0698],\n",
      "          [ 0.3684,  0.3684,  0.3684,  ...,  0.1124,  0.1266,  0.1124],\n",
      "          [ 0.3684,  0.3684,  0.3684,  ...,  0.1409,  0.1409,  0.1266]]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for imgs, file_ids in tqdm(cifar10_loader_test, desc=\"Predicting with FAISS\"):\n",
    "    print(file_ids)\n",
    "    print(imgs)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset CIFAR10\n",
      "    Number of datapoints: 50000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=224, interpolation=bicubic, max_size=None, antialias=True)\n",
      "               CenterCrop(size=(224, 224))\n",
      "               <function _convert_image_to_rgb at 0x7fbe90d57d90>\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711))\n",
      "           )\n",
      "Dataset CIFAR10\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=224, interpolation=bicubic, max_size=None, antialias=True)\n",
      "               CenterCrop(size=(224, 224))\n",
      "               <function _convert_image_to_rgb at 0x7fbe90d57d90>\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711))\n",
      "           )\n",
      "\n",
      "<class 'torchvision.datasets.cifar.CIFAR10'>\n"
     ]
    }
   ],
   "source": [
    "print(cifar10_dataset_train)\n",
    "print(cifar10_dataset_test)\n",
    "print()\n",
    "print(type(cifar10_dataset_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_preprocess_fn(imgs):\n",
    "    \"\"\"\n",
    "    Preprocess CLIP embeddings - normalize for cosine similarity.\n",
    "    \"\"\"\n",
    "    device = next(clip_model.parameters()).device\n",
    "    imgs = imgs.to(device)\n",
    "    \n",
    "    clip_model.eval()\n",
    "    with torch.no_grad():\n",
    "        features = clip_model.encode_image(imgs)\n",
    "        features = F.normalize(features, p=2, dim=-1)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building FAISS Index: 100%|██████████| 782/782 [05:59<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index built with 50000 entries.\n"
     ]
    }
   ],
   "source": [
    "faiss_labels, faiss_index = build_faiss_index(\n",
    "    dataloader=cifar10_loader_train,\n",
    "    preprocess_fn=clip_preprocess_fn,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def predict_with_faiss(dataloader, preprocess_fn, faiss_index, faiss_labels,\n",
    "                              device=\"cuda\", top_k=5, distractor_classes=None):\n",
    "    \"\"\"\n",
    "    Predict top-k classes using FAISS with duplicate and distractor handling.\n",
    "\n",
    "    Args:\n",
    "        dataloader (DataLoader): DataLoader for test data.\n",
    "        preprocess_fn (function): Preprocessing function for embeddings.\n",
    "        faiss_index (faiss.Index): Prebuilt FAISS index.\n",
    "        faiss_labels (np.ndarray): Labels corresponding to FAISS index.\n",
    "        device (str): Device to run computations (\"cuda\" or \"cpu\").\n",
    "        top_k (int): Number of predictions to return.\n",
    "        distractor_classes (set): Classes treated as distractors.\n",
    "\n",
    "    Returns:\n",
    "        ground_truth (list): List of true labels.\n",
    "        results (list): List of top-k predictions.\n",
    "    \"\"\"\n",
    "    assert faiss_index is not None, \"FAISS index is not built. Call build_faiss_index_global() first.\"\n",
    "\n",
    "    if distractor_classes is None:\n",
    "        distractor_classes = {}\n",
    "\n",
    "    results = []\n",
    "    ground_truth = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in tqdm(dataloader, desc=\"Predicting with FAISS\"):\n",
    "            imgs = imgs.to(device)\n",
    "            embeddings = preprocess_fn(imgs)\n",
    "\n",
    "            features = np.ascontiguousarray(embeddings.cpu().numpy(), dtype=np.float32)\n",
    "            distances, indices = faiss_index.search(features, top_k * 2)\n",
    "\n",
    "            for i in range(len(features)):\n",
    "                top_classes = faiss_labels[indices[i]].tolist()\n",
    "\n",
    "                seen = set()\n",
    "                filtered_classes = []\n",
    "                for cls in top_classes:\n",
    "                    if cls not in seen:\n",
    "                        filtered_classes.append(cls)\n",
    "                        seen.add(cls)\n",
    "                    if len(filtered_classes) == top_k:\n",
    "                        break\n",
    "\n",
    "                predictions = []\n",
    "                if filtered_classes and filtered_classes[0] in distractor_classes:\n",
    "                    predictions.append(filtered_classes[0])\n",
    "                    predictions.append(-1)\n",
    "                    predictions.extend(filtered_classes[1:])\n",
    "                else:\n",
    "                    predictions = filtered_classes\n",
    "\n",
    "                predictions = predictions[:top_k]\n",
    "\n",
    "                if len(predictions) < top_k:\n",
    "                    predictions += [-1] * (top_k - len(predictions))\n",
    "\n",
    "                results.append(predictions)\n",
    "\n",
    "            ground_truth.extend(lbls.cpu().numpy().tolist())\n",
    "\n",
    "    return ground_truth, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting with FAISS: 100%|██████████| 157/157 [02:12<00:00,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "ground_truth, predictions = predict_with_faiss(\n",
    "    dataloader=cifar10_loader_test,\n",
    "    preprocess_fn=clip_preprocess_fn,\n",
    "    faiss_index=faiss_index,\n",
    "    faiss_labels=faiss_labels,\n",
    "    device=device,\n",
    "    top_k=5,\n",
    "    distractor_classes=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 1 accuracy 0.9354\n"
     ]
    }
   ],
   "source": [
    "accuracy_top1 = compute_topk_accuracy(ground_truth, predictions, top_k=1)\n",
    "print('top 1 accuracy', accuracy_top1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 2 accuracy 0.9747\n"
     ]
    }
   ],
   "source": [
    "accuracy_top2 = compute_topk_accuracy(ground_truth, predictions, top_k=2)\n",
    "print('top 2 accuracy', accuracy_top2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 5 accuracy 0.988\n"
     ]
    }
   ],
   "source": [
    "accuracy_top5 = compute_topk_accuracy(ground_truth, predictions, top_k=5)\n",
    "print('top 5 accuracy', accuracy_top5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10-la-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
